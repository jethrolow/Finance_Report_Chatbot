{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering\n",
    "\n",
    "Prompt Engineering Techniques explored:\n",
    "\n",
    "1. System message experimentation\n",
    "1. Chain-of-Thought with zero-shot and few-shot prompting\n",
    "1. Condense message experimentation\n",
    "1. Combining all together (final prompt)\n",
    "1. Also: Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jethro/anaconda3/envs/langchain/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import(\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain import OpenAI, ConversationChain\n",
    "from langchain.memory import ConversationBufferWindowMemory, ConversationBufferMemory\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.agents import Tool\n",
    "from langchain.document_loaders import PyPDFLoader, UnstructuredPDFLoader\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import PyPDFLoader, UnstructuredPDFLoader\n",
    "\n",
    "from tree_of_thoughts.openaiModels import OpenAILanguageModel\n",
    "from tree_of_thoughts.treeofthoughts import MonteCarloTreeofThoughts\n",
    "\n",
    "import tabula\n",
    "\n",
    "import os\n",
    "\n",
    "from PyPDF2 import PdfReader\n",
    "import pandas as df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in openai API key\n",
    "os.environ['OPENAI_API_KEY'] =\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document used and test cases\n",
    "\n",
    "For the purpose of experimentation, let's use the Tesla Annual Report for year 2022. This document contains both text and tabular information (at the end of document), hence it will be a good test document for our prompt engineering. The document is stored in the \"./data\" folder.\n",
    "\n",
    "We should also include some basic test cases beforehand. This will make it easy to check if the prompts are giving us the correct output. Some test cases are defined here for reference.\n",
    "\n",
    "* Numbers. To test tabular data. \n",
    "\n",
    "1. What are the total assets and liabilities for the year 2022? Answer: 82338 million and 36440 million.\n",
    "1. What is the Income before income taxes for the year  2020, 2021 and 2022? Answer: 1,154, 6,343 and 13,719 respectively.\n",
    "1. What is the Comprehensive income attributable to common stockholders for year 2022?\" Answer: 12141 million\n",
    "1. What is the gross profit in 2019?\n",
    "Note: This tests if the model will give a truthful answer or hallucinates the numbers.\n",
    "\n",
    "* General Questions (open-ended)\n",
    "1. What does Tesla do? And what types of businesses is Tesla involved in?\n",
    "1. How is the financial health of Tesla?\n",
    "1. What kind of technologies does Tesla invest in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# template code to be used for testing of prompts\n",
    "query_1 = \"What are the total assets and liabilities for the year 2022 in the consolidated balance sheet?\"\n",
    "query_2 = \"What is the Income before income taxes for the year  2020, 2021 and 2022?\"\n",
    "query_3 = \"What is the Comprehensive income attributable to common stockholders for year 2022?\"\n",
    "query_4 = \"What is the gross profit in 2019?\"\n",
    "queries_num = [query_1,query_2,query_3,query_4]\n",
    "\n",
    "query_5 = \"What does Tesla do? And what types of businesses is Tesla involved in?\"\n",
    "query_6 = \"How is the financial health of Tesla?\"\n",
    "query_7 = \"What kind of technologies does Tesla invest in?\"\n",
    "queries_gen = [query_5, query_6, query_7]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Guidelines for prompt engineering\n",
    "\n",
    "see: https://www.promptingguide.ai/introduction/tips\n",
    "\n",
    "* Start Simple  \n",
    "Slowly add on more complexity\n",
    "\n",
    "* Focus on the instruction  \n",
    "using commands to instruct the model what you want to achieve, such as \"Write\", \"Classify\", \"Summarize\", \"Translate\", \"Order\", etc.  \n",
    "Another recommendation is to use some clear separator like \"###\" to separate the instruction and context.\n",
    "\n",
    "\n",
    "        ### Instruction ###  \n",
    "        Translate the text below to Spanish:\n",
    "        Text: \"hello!\"\n",
    "\n",
    "        \n",
    "* Specificity\n",
    "Be very specific about the instruction and task you want the model to perform. Thinking about how specific and detailed you should be. Including too many unnecessary details is not necessarily a good approach. The details should be relevant and contribute to the task at hand.\n",
    "\n",
    "* Avoid Impreciseness  \n",
    "It's often better to be specific and direct. The analogy here is very similar to effective communication -- the more direct, the more effective the message gets across.\n",
    "\n",
    "* To do or not to do  \n",
    "Avoid saying what not to do but say what to do instead. This encourages more specificity and focuses on the details that lead to good responses from the model.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruction Prompt Experimentation\n",
    "\n",
    "Here, we shall experiment with the different kinds of system prompts. To follow the guidelines above. The instruction prompt also forms the system prompt in the ChatPromptTemplate format.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-05 19:48:58,648 - INFO - Loading faiss with AVX2 support.\n",
      "2023-07-05 19:48:58,691 - INFO - Successfully loaded faiss with AVX2 support.\n"
     ]
    }
   ],
   "source": [
    "# try baseline case with default prompt template from RetrievalQA\n",
    "FILE_PATH = \"../data/Tesla_Annual_Report_2022.pdf\"\n",
    "loader = PyPDFLoader(FILE_PATH)\n",
    "data = loader.load()\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vector_store = FAISS.from_documents(data, embeddings)\n",
    "qa = RetrievalQA.from_chain_type(llm=ChatOpenAI(temperature = 0.1), chain_type=\"stuff\", retriever=vector_store.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], output_parser=None, partial_variables={}, template=\"Use the following pieces of context to answer the users question. \\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\n{context}\", template_format='f-string', validate_template=True), additional_kwargs={}),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], output_parser=None, partial_variables={}, template='{question}', template_format='f-string', validate_template=True), additional_kwargs={})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect what the default prompt message is.\n",
    "qa.combine_documents_chain.llm_chain.prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What kind of technologies does Tesla invest in?',\n",
       " 'result': 'Tesla invests in a variety of technologies related to automotive, battery and powertrain, vehicle control and infotainment software, self-driving development and artificial intelligence, energy generation and storage, design and engineering, and financial services. Some specific areas of focus include electric powertrain systems, battery cell technology, vehicle control software, self-driving technologies, solar energy systems, and energy storage products. Tesla also places a strong emphasis on intellectual property protection and invests in innovative designs and proprietary technologies.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output using the default prompt message\n",
    "question = query_7\n",
    "qa({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"\"\"### Instruction ###\n",
    "Use the following pieces of context to answer the users question.\n",
    "### Guidelines ###\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Your role is as a financial analyst\n",
    "No matter what the question is, you should always answer it in the context provided below.\n",
    "If you are unsure of the answer, just say \"I do not know\"\n",
    "### context ###\n",
    "{context}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction ###\n",
      "Use the following pieces of context to answer the users question.\n",
      "### Guidelines ###\n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "Your role is as a financial analyst\n",
      "No matter what the question is, you should always answer it in the context provided below.\n",
      "If you are unsure of the answer, just say \"I do not know\"\n",
      "### context ###\n",
      "{context}\n"
     ]
    }
   ],
   "source": [
    "print(system_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "human_template = \"{question}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "chain_type_kwargs = {\"prompt\": chat_prompt}\n",
    "qa = RetrievalQA.from_chain_type(llm=ChatOpenAI(temperature = 0.1), chain_type=\"stuff\", retriever=vector_store.as_retriever(), chain_type_kwargs= chain_type_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What kind of technologies does Tesla invest in?',\n",
       " 'result': 'Tesla invests in a variety of technologies related to automotive, battery and powertrain, vehicle control and infotainment software, self-driving development and artificial intelligence, energy generation and storage, design and engineering, and environmental, social, and governance (ESG) initiatives. Some specific areas of investment include powertrain engineering, electric powertrain systems, battery cell chemistry and manufacturing processes, vehicle control software, self-driving technologies, energy storage systems, solar energy systems, intellectual property protection, sustainable manufacturing practices, and customer service and warranty programs.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output using the revised_1 prompt message\n",
    "question = query_7\n",
    "qa({\"query\": question})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "* As can be seen, the new prompt gives a more detailed answer than the old prompt.\n",
    "* After checking, it can be seen that both prompts are factually accurate.\n",
    "* The new prompts, with more instructions and greater precision and clearly defined ## instruction ##, ## guidelines ## and ## context ## does help to give more detailed prompts from the example shown.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain-of-thought with zero-shot prompting and few-shot prompting\n",
    "\n",
    "What is chain-of-thought prompting: Introduced in Wei et al., chain-of-thought (CoT) prompting enables complex reasoning capabilities through intermediate reasoning steps. You can combine it with few-shot prompting to get better results on more complex tasks that require reasoning before responding.\n",
    "\n",
    "Link: https://arxiv.org/abs/2201.11903\n",
    "\n",
    "In the initial query with base prompt, it was shown that the model had difficulty with query_3 = \"What is the year on year increase in the gross profit from 2020 to 2022 in percentages?\" As this requires look ahead and higher order thinking. In this example, we try to see if we can use chain-of-thought to resolve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try baseline case with default prompt template from RetrievalQA\n",
    "def get_text_from_pdf(fs_pdf_docs: list):\n",
    "    text_output = \"\"\n",
    "    for pdf_file in fs_pdf_docs:\n",
    "        pdf_reader = PdfReader(pdf_file)\n",
    "        for page in pdf_reader.pages:\n",
    "            text_output = text_output + page.extract_text()\n",
    "    return text_output\n",
    "\n",
    "def get_chunk_from_text(whole_text: str):\n",
    "    text_split = RecursiveCharacterTextSplitter(\n",
    "        separators = [\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "        chunk_size = 1000,\n",
    "        chunk_overlap = 200,\n",
    "        length_function = len\n",
    "    )\n",
    "    chunks = text_split.split_text(whole_text)\n",
    "    return chunks\n",
    "\n",
    "def get_vectorstore_from_chucks(chunks):\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorstore = FAISS.from_texts(texts = chunks, embedding = embeddings)\n",
    "    return vectorstore\n",
    "\n",
    "text = get_text_from_pdf([FILE_PATH])\n",
    "chunks = get_chunk_from_text(text)\n",
    "vector_store = get_vectorstore_from_chucks(chunks)\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=ChatOpenAI(temperature = 0.1), chain_type=\"stuff\", retriever=vector_store.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is the year on year increase in the gross profit from 2020 to 2022 in percentages?',\n",
       " 'result': 'The year-on-year increase in gross profit from 2020 to 2022 is not provided in the given context.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output using the default prompt message\n",
    "# As can be seen, the model got lost in the context and is unable to even retrieve information on the gross profit\n",
    "question = query_3\n",
    "qa({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with COT with zero-shot prompting by adding \"let;s think this step by step\"\n",
    "system_template = \"Use the following pieces of context to answer the users question. \\nIf you don't know the answer, just say that you don't know, don't try to make up an answer. Let's think step by step.\\n----------------\\n{context}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "human_template = \"{question}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "chain_type_kwargs = {\"prompt\": chat_prompt}\n",
    "qa = RetrievalQA.from_chain_type(llm=ChatOpenAI(temperature = 0.1), chain_type=\"stuff\", retriever=vector_store.as_retriever(), chain_type_kwargs= chain_type_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is the year on year increase in the gross profit from 2020 to 2022 in percentages?',\n",
       " 'result': 'To calculate the year-on-year increase in gross profit from 2020 to 2022 in percentages, we need the gross profit figures for both years. However, the provided information only includes the gross profit figures for 2021 and 2022. Without the gross profit figure for 2020, we cannot calculate the exact year-on-year increase in percentages.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There is an improvement in the output. However, it response is still not complete. \n",
    "question = query_3\n",
    "qa({\"query\": question})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "* The base prompt gave the worst reply. It did not manage to get the figures of gross profit from year 2020. There could be an issue with the way the data is read in or the similarity search with the context.\n",
    "* The zero-shot CoT prompt gave a much improved reply, showing that it understood the context and the way to calculate the figures. However, the figures are not correct. Upon further inspection, there it read the data from the wrong table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the following pieces of context to answer the users question.\n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
      "Let's think step by step.\n",
      "---------------------\n",
      "Q: What is the percentage increase in gross profit margin from year 2021 to year 2022.\n",
      "A: The gross profit margin in year 2021 is 13606. The gross profit margin in year 2022 is 20853. Using the formula Percentage Increase = ((New Value - Old Value) / Old Value), the gross profit margin is 53.26%.\n",
      "Q: What is the net income from financial year 2021 and 2022 combined?\n",
      "A: The net income for financial year 2021 is 300 million. The net income for financial year 2022 is 200 million. Therefore, the combined net income is 500 million.\n",
      "### context ###\n",
      "{context}\n"
     ]
    }
   ],
   "source": [
    "# Let's introduce CoT with few-shot prompting\n",
    "system_template = \"\"\"Use the following pieces of context to answer the users question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "Let's think step by step.\n",
    "---------------------\n",
    "Q: What is the percentage increase in gross profit margin from year 2021 to year 2022.\n",
    "A: The gross profit margin in year 2021 is 13606. The gross profit margin in year 2022 is 20853. Using the formula Percentage Increase = ((New Value - Old Value) / Old Value), the gross profit margin is 53.26%.\n",
    "Q: What is the net income from financial year 2021 and 2022 combined?\n",
    "A: The net income for financial year 2021 is 300 million. The net income for financial year 2022 is 200 million. Therefore, the combined net income is 500 million.\n",
    "### context ###\n",
    "{context}\"\"\"\n",
    "\n",
    "print(system_template)\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "human_template = \"{question}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "chain_type_kwargs = {\"prompt\": chat_prompt}\n",
    "qa = RetrievalQA.from_chain_type(llm=ChatOpenAI(temperature = 0.0), chain_type=\"stuff\", retriever=vector_store.as_retriever(), chain_type_kwargs= chain_type_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': ' What is the gross profit for year 2021 and year 2022 combined?',\n",
       " 'result': 'The gross profit for the year 2021 is $13,735 million. The gross profit for the year 2022 is $20,565 million. Therefore, the combined gross profit for the two years is $34,300 million.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try another question for CoT with few-shot prompting\n",
    "question = \" What is the gross profit for year 2021 and year 2022 combined?\"\n",
    "qa({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': ' What is the gross profit for year 2021 and year 2022 combined?',\n",
       " 'result': 'The gross profit for the years 2021 and 2022 combined is $27,470 million.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try with base prompt\n",
    "qa = RetrievalQA.from_chain_type(llm=ChatOpenAI(temperature = 0.1), chain_type=\"stuff\", retriever=vector_store.as_retriever())\n",
    "question = \" What is the gross profit for year 2021 and year 2022 combined?\"\n",
    "qa({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], output_parser=None, partial_variables={}, template=\"Use the following pieces of context to answer the users question. \\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\n{context}\", template_format='f-string', validate_template=True), additional_kwargs={}),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], output_parser=None, partial_variables={}, template='{question}', template_format='f-string', validate_template=True), additional_kwargs={})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.combine_documents_chain.llm_chain.prompt.messages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "* The CoT with few-shot prompt is able to explain out the reasoning of how it got to the final answer. However, it read the data from the wrong table. (See page 88 on segment reporting)\n",
    "* The base prompt did not explain the thought process and gave a wrong answer as well."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condense QA Prompt\n",
    "The ConversationalRetrievalChain is a component of the Langchain system that combines chat history, question condensing, semantic search, and question answering to provide a response. On the backend, the ConversationalRetrievalChain performs the following steps:\n",
    "\n",
    "It condenses the current question and the chat history into a standalone question. This is done to create a standalone vector for retrieval.\n",
    "\n",
    "It uses a retriever, which can be created from a vector store, to look up relevant documents based on the condensed question.\n",
    "\n",
    "It passes the retrieved documents and the original question to a question answering chain to generate a response.\n",
    "\n",
    "It returns the answer to the user.\n",
    "\n",
    "* We can update the condense_QA_prompt that performs step 1 to summarize the current question and the chat history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "\n",
    "chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=vector_store.as_retriever(),\n",
    "    chain_type=\"stuff\",\n",
    "    return_source_documents=True,\n",
    "    output_key=\"answer\",\n",
    "    return_generated_question = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['chat_history', 'question'], output_parser=None, partial_variables={}, template='Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone question:', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the default QA prompt\n",
    "chain.question_generator.prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What kind of technologies does Tesla invest in?\n",
      "Tesla invests in a variety of technologies, including electric vehicle technology, autonomous driving technology, energy generation and storage technology, and artificial intelligence. They continuously develop and improve their electric vehicle technology, including advanced driver assist systems and autonomous driving capabilities. They also invest in energy storage products, such as Powerwall and Megapack, which utilize lithium-ion battery technology. Additionally, Tesla applies their artificial intelligence learnings to robotics and has showcased a robotic humanoid controlled by their AI system.\n",
      "-------------------------------------------------\n",
      "Out of all the technologies, which one is the most interesting and has the most potential?\n",
      "Based on the given context, it is difficult to determine which technology has the most potential as it depends on individual perspectives and priorities. However, some technologies mentioned that have significant potential include autonomous driving technology (Autopilot and FSD), energy storage products (leveraging vehicle component technologies), solar energy systems (including Solar Roof), and the development of robotics using artificial intelligence. Each of these technologies has the potential to revolutionize their respective industries and contribute to a more sustainable future.\n",
      "-------------------------------------------------\n",
      "Tell me more about the autonomous driving technology.\n",
      "Tesla's autonomous driving technology is currently offered in their vehicles under the Autopilot and Full Self-Driving (FSD) options. These systems provide safety and convenience functionality that relieves drivers of tedious and potentially dangerous aspects of road travel. However, it is important to note that the driver is still ultimately responsible for controlling the vehicle.\n",
      "\n",
      "Tesla's autonomous driving technology is continuously improved through over-the-air updates. The company aims to establish an autonomous Tesla ride-hailing network in the future, which would allow them to access a new customer base as transportation modes evolve.\n",
      "\n",
      "In addition to automotive applications, Tesla applies its artificial intelligence learnings from self-driving technology to the field of robotics. They have showcased a robotic humanoid called Optimus, which is controlled by the same AI system used in their vehicles.\n",
      "\n",
      "It is worth mentioning that the development and deployment of autonomous driving technology are subject to various international, federal, and state regulations. These regulations may affect the design, performance, sale, registration, and operation of Autopilot, FSD Capability, and future self-driving vehicles. Compliance with evolving regulations and potential conflicts between different regulations could impact Tesla's business.\n"
     ]
    }
   ],
   "source": [
    "# Let's use the base prompt to see how the output standalone question looks like\n",
    "chat_history = []\n",
    "question = query_7\n",
    "print(question)\n",
    "result = chain({\"question\": question, \"chat_history\": chat_history})\n",
    "print(result['answer'])\n",
    "chat_history.append((question, result[\"answer\"]))\n",
    "print(\"-------------------------------------------------\")\n",
    "\n",
    "sub_question_1 = \"Out of all the technologies, which one is the most interesting and has the most potential?\"\n",
    "print(sub_question_1)\n",
    "result = chain({\"question\": sub_question_1, \"chat_history\": chat_history})\n",
    "print(result['answer'])\n",
    "chat_history.append((question, result[\"answer\"]))\n",
    "print(\"-------------------------------------------------\")\n",
    "\n",
    "sub_question_2 = \"Tell me more about the autonomous driving technology.\"\n",
    "print(sub_question_2)\n",
    "result = chain({\"question\": sub_question_2, \"chat_history\": chat_history})\n",
    "print(result['answer'])\n",
    "chat_history.append((question, result[\"answer\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What are some details about Tesla's autonomous driving technology?\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the output after condensing history and new question\n",
    "result['generated_question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_template = \"\"\"\n",
    "Given the following chat history and a follow up question, rephrase the\\\n",
    "follow up question to be a standalone question.\\\n",
    "The follow up question may not always be based on the chat history.\\\n",
    "If follow up question is not based on the chat history, do not rephrase it.\\\n",
    "If follow up question is not based on the chat history, you should still answer it\\\n",
    "in the context given below.\\\n",
    "If the question is not related to the context below, just say that \"I don't know\".\\\n",
    "Chat History:{chat_history}\\\n",
    "Follow Up Question: {question}\\\n",
    "Standalone Question:\n",
    "\"\"\"\n",
    "\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(memory_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "\n",
    "chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=vector_store.as_retriever(),\n",
    "    chain_type=\"stuff\",\n",
    "    return_source_documents=True,\n",
    "    output_key=\"answer\",\n",
    "    return_generated_question = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What kind of technologies does Tesla invest in?\n",
      "Tesla invests in a variety of technologies related to electric vehicles, energy generation, and storage. Some of the key technologies they focus on include:\n",
      "\n",
      "1. Electric Vehicle Technology: Tesla invests heavily in developing advanced electric vehicle technology, including battery technology, electric drivetrains, and autonomous driving systems.\n",
      "\n",
      "2. Battery Technology: Tesla is known for its expertise in battery technology and invests in developing high-performance and long-lasting lithium-ion batteries for its vehicles and energy storage products.\n",
      "\n",
      "3. Autonomous Driving: Tesla is at the forefront of autonomous driving technology and invests in developing advanced driver-assist systems and full self-driving capabilities for its vehicles.\n",
      "\n",
      "4. Energy Storage: Tesla invests in energy storage technology, including the development of large-scale battery systems like the Megapack, which can store and distribute renewable energy.\n",
      "\n",
      "5. Solar Energy: Tesla offers solar energy systems for residential, commercial, and industrial customers. They invest in solar panel technology and software capabilities for optimizing energy generation and storage.\n",
      "\n",
      "6. Artificial Intelligence: Tesla applies its artificial intelligence expertise to various areas, including self-driving technology and robotics.\n",
      "\n",
      "Overall, Tesla's investments focus on advancing sustainable transportation and clean energy solutions.\n",
      "-------------------------------------------------\n",
      "Out of all the technologies, which one is the most interesting and has the most potential?\n",
      "Based on the provided context, it is difficult to determine which technology has the most potential as it depends on individual perspectives and market demands. However, some technologies mentioned that have significant potential include autonomous driving technology (Autopilot and FSD), energy storage products (including battery systems and energy dispatch software), solar energy systems (including Solar Roof and solar inverters), and direct sales channels (website and company-owned stores). These technologies have the potential to revolutionize transportation, energy generation, and storage industries.\n",
      "-------------------------------------------------\n",
      "Tell me more about the autonomous driving technology.\n",
      "Some key features and advancements in Tesla's autonomous driving technology include:\n",
      "\n",
      "1. Autopilot: Tesla's Autopilot feature provides advanced driver assist systems that can assist with tasks such as steering, accelerating, and braking. It uses sensors and cameras to detect and respond to the vehicle's surroundings.\n",
      "\n",
      "2. Full Self-Driving (FSD) Capability: Tesla's FSD Capability is an advanced version of Autopilot that aims to achieve full autonomy. It includes features like automatic lane changing, navigating on highways, and parking.\n",
      "\n",
      "3. Over-the-Air Updates: Tesla regularly updates its vehicles' software through over-the-air updates. This allows for continuous improvement and the addition of new features to the autonomous driving technology.\n",
      "\n",
      "4. Neural Networks: Tesla uses neural networks to process and analyze data from its vehicles' sensors and cameras. These neural networks are constantly trained and improved to enhance the performance of the autonomous driving technology.\n",
      "\n",
      "5. Vision-Based Technologies: Tesla primarily relies on vision-based technologies, such as cameras, for its autonomous driving systems. This approach allows for a comprehensive understanding of the vehicle's surroundings.\n",
      "\n",
      "6. Robotics: Tesla is applying its artificial intelligence learnings from self-driving technology to the field of robotics. For example, they have developed a robotic humanoid called Optimus, which is controlled by the same AI system.\n",
      "\n",
      "It's important to note that while Tesla's autonomous driving technology offers advanced driver assist systems, the driver is still ultimately responsible for controlling the vehicle.\n"
     ]
    }
   ],
   "source": [
    "# Let's use the improved prompt to see how the output standalone question looks like\n",
    "chat_history = []\n",
    "question = query_7\n",
    "print(question)\n",
    "result = chain({\"question\": question, \"chat_history\": chat_history})\n",
    "print(result['answer'])\n",
    "chat_history.append((question, result[\"answer\"]))\n",
    "print(\"-------------------------------------------------\")\n",
    "\n",
    "sub_question_1 = \"Out of all the technologies, which one is the most interesting and has the most potential?\"\n",
    "print(sub_question_1)\n",
    "result = chain({\"question\": sub_question_1, \"chat_history\": chat_history})\n",
    "print(result['answer'])\n",
    "chat_history.append((question, result[\"answer\"]))\n",
    "print(\"-------------------------------------------------\")\n",
    "\n",
    "sub_question_2 = \"Tell me more about the autonomous driving technology.\"\n",
    "print(sub_question_2)\n",
    "result = chain({\"question\": sub_question_2, \"chat_history\": chat_history})\n",
    "print(result['answer'])\n",
    "chat_history.append((question, result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What are some key features and advancements in Tesla's autonomous driving technology?\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the output after condensing history and new question\n",
    "# for improved condensed qa prompt\n",
    "result['generated_question']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining all together (final prompt template used)\n",
    "Now that we have experimented with different methods of prompt engineering and observed the outputs, we can combine the knowledge to generate the eventual prompt used for the app deployment.\n",
    "\n",
    "**Main observations from prompt engineering:**\n",
    "1. Modifying the system prompt with instructions, guidelines and context gives answers with more details and nuances. The answers are factual and accurate.\n",
    "1. CoT with zero-shot prompting is able to produce answers which are relevant and contextual. It is also highly verbose and explains with rich details on how it arrived at the final answer.\n",
    "1. CoT with few-shot prompting gave similar answers to CoT with zero-shot prompting. This method also used more tokens, leaving less token space available for the context. Hence, it is better not to use CoT with few-shot prompting for our use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA prompt\n",
    "system_template = \"\"\"### Instruction ###\n",
    "Use the following pieces of context to answer the users question.\n",
    "### Guidelines ###\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Your role is as a financial analyst\n",
    "No matter what the question is, you should always answer it in the context provided below.\n",
    "If you are unsure of the answer, just say \"I do not know\"\n",
    "### context ###\n",
    "{context}\"\"\"\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "human_template = \"{question}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": chat_prompt}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condensed QA prompt\n",
    "memory_template = \"\"\"\n",
    "Given the following chat history and a follow up question, rephrase the\\\n",
    "follow up question to be a standalone question.\\\n",
    "The follow up question may not always be based on the chat history.\\\n",
    "If follow up question is not based on the chat history, do not rephrase it.\\\n",
    "If follow up question is not based on the chat history, you should still answer it\\\n",
    "in the context given below.\\\n",
    "If the question is not related to the context below, just say that \"I don't know\".\\\n",
    "Chat History:{chat_history}\\\n",
    "Follow Up Question: {question}\\\n",
    "Standalone Question:\n",
    "\"\"\"\n",
    "\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(memory_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Chain\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "\n",
    "chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=vector_store.as_retriever(),\n",
    "    chain_type=\"stuff\",\n",
    "    return_source_documents=True,\n",
    "    output_key=\"answer\",\n",
    "    condense_question_prompt=CONDENSE_QUESTION_PROMPT,\n",
    "    combine_docs_chain_kwargs= chain_type_kwargs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='We also work with a wide variety of hospitality, retail and public destinations, as well as businesses with commuting employees,\\nto offer additional charging options for our customers, as well as single-family homeowners and multi-family residential entities, todeploy home charging solutions.7In-App Upgrades\\nAs our vehicles are capable of being updated remotely over-the-air, our customers may purchase additional paid options and\\nfeatures through the Tesla app or through the in-vehicle user interface. We expect that this functionality will also allow us to offercertain options and features on a subscription basis in the future.\\nEnergy Generation and Storage\\nWe market and sell our solar and energy storage products to residential, commercial and industrial customers and utilities', metadata={}),\n",
       " Document(page_content='Energy Generation and Storage\\nWe market and sell our solar and energy storage products to residential, commercial and industrial customers and utilities\\nthrough a variety of channels, including through our website, stores and galleries, as well as through our network of channel partners,and in the case of some commercial customers, through PPA transactions. We emphasize simplicity, standardization and accessibilityto make it easy and cost-effective for customers to adopt clean energy, while reducing our customer acquisition costs.\\nService and Warranty\\nAutomotive\\nServiceWe provide service for our electric vehicles at our company-owned service locations and through Tesla Mobile Service', metadata={}),\n",
       " Document(page_content='and the significant capital outlay required to do so;\\n• Build Gigafactory Nevada, the largest lithium-ion battery factory in the world, so that we can scale most effectively;• Expand into energy generation and storage through the acquisition of SolarCity Corporation in 2016 to create a\\nvertically integrated sustainable energy company and empower individual consumers to be their own utility;\\n• Deploy FSD Beta incrementally, resulting in over 130 million cumulative miles driven with FSD Beta to date; and• Compensate our CEO only if other stockholders realize tremendous value.\\nThese and other similar decisions were made due to our corporate governance structure and, ultimately, decisions like these\\nare what differentiate Tesla from other companies.\\nYear-Round Engagement\\nOur Board continuously evaluates our corporate governance structure, practices and policies, and weighs stakeholder', metadata={}),\n",
       " Document(page_content='We intend to establish in the future an autonomous Tesla ride-hailing network, which we expect would also allow us to access a\\nnew customer base even as modes of transportation evolve.\\nWe are also applying our artificial intelligence learnings from self-driving technology to the field of robotics. For example, in\\n2022 we previewed Optimus, a robotic humanoid which is controlled by the same AI system.\\nEnergy Generation and Storage\\nEnergy Storage ProductsWe leverage many of the component-level technologies from our vehicles in our energy storage products. By taking a modular\\napproach to the design of battery systems, we can optimize manufacturing capacity of our energy storage products. Additionally, ourexpertise in power electronics enables our battery systems to interconnect with electricity grids while providing fast-acting systems forpower injection and absorption. We have also developed software to remotely control and dispatch our energy storage systems.\\nSolar Energy Systems', metadata={})]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = chain({\"question\": question, \"chat_history\": chat_history})\n",
    "\n",
    "chat_history.append((question, result[\"answer\"]))\n",
    "\n",
    "result[\"source_documents\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result[\"source_documents\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created our final prompt template, let's run through all the 7 queries and see the output of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the total assets and liabilities for the year 2022 in the consolidated balance sheet?\n",
      "The total assets for the year 2022 in the consolidated balance sheet are $82,338 million. The total liabilities for the year 2022 in the consolidated balance sheet are $36,440 million.\n",
      "---------------------------------------------\n",
      "What is the Income before income taxes for the year  2020, 2021 and 2022?\n",
      "The income before income taxes for the year 2020 was $1,154 million, for the year 2021 was $6,343 million, and for the year 2022 was $13,719 million.\n",
      "---------------------------------------------\n",
      "What is the Comprehensive income attributable to common stockholders for year 2022?\n",
      "The Comprehensive income attributable to common stockholders for the year 2022 is $12,141 million.\n",
      "---------------------------------------------\n",
      "What is the gross profit in 2019?\n",
      "I do not know the gross profit in 2019 as the provided context only includes information for the years 2020, 2021, and 2022.\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for query in queries_num:\n",
    "    chat_history = []\n",
    "    result = chain({\"question\": query, \"chat_history\": chat_history})\n",
    "    print(result['question'])\n",
    "    print(result['answer'])\n",
    "    print(\"---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What does Tesla do? And what types of businesses is Tesla involved in?\n",
      "Tesla is a company that primarily focuses on the design, development, manufacturing, and sale of electric vehicles. They also provide energy generation and storage solutions through their solar and energy storage products. Additionally, Tesla offers services such as vehicle maintenance and repairs.\n",
      "\n",
      "In terms of the types of businesses Tesla is involved in, they work with a wide range of industries. They collaborate with hospitality, retail, and public destinations to provide charging options for their customers. They also work with businesses that have commuting employees to offer charging solutions. Furthermore, Tesla markets and sells their solar and energy storage products to residential, commercial, and industrial customers, as well as utilities.\n",
      "---------------------------------------------\n",
      "How is the financial health of Tesla?\n",
      "As a financial analyst, I can provide some insights into Tesla's financial health based on the information provided. However, please note that the context does not explicitly mention the current financial status of Tesla. \n",
      "\n",
      "Tesla has experienced significant growth in recent years, with its annual revenue reaching approximately $11.8 billion in 2017. However, in order to achieve certain operational milestones, Tesla would need to increase its revenue by more than $163 billion. This indicates that Tesla has ambitious targets for growth.\n",
      "\n",
      "It is important to consider that Tesla faces challenges in maintaining long-term financial viability and business prospects. These challenges include limited operating history compared to established competitors, customer unfamiliarity with their products, potential delays in scaling manufacturing and delivery operations, competition in the electric vehicle market, and uncertainty regarding the future of electric vehicles.\n",
      "\n",
      "Tesla's financial statements are audited by an independent registered public accounting firm, PricewaterhouseCoopers LLP. The Audit Committee oversees the activities related to financial controls and statements.\n",
      "\n",
      "Based on this information, it is difficult to provide a definitive assessment of Tesla's current financial health. It would require a more detailed analysis of their financial statements, market conditions, and other relevant factors.\n",
      "---------------------------------------------\n",
      "What kind of technologies does Tesla invest in?\n",
      "Tesla invests in a variety of technologies, including autonomous driving technology, artificial intelligence, robotics, energy generation and storage, and battery technology. They leverage their expertise in power electronics and battery systems to develop energy storage products such as Powerwall and Megapack. They also work on solar energy systems and offer charging options for electric vehicles. Additionally, Tesla focuses on developing software capabilities for remote control and dispatch of their energy storage systems.\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for query in queries_gen:\n",
    "    chat_history = []\n",
    "    result = chain({\"question\": query, \"chat_history\": chat_history})\n",
    "    print(result['question'])\n",
    "    print(result['answer'])\n",
    "    print(\"---------------------------------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
